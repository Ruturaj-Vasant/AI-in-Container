# AI-in-Container

MNIST-in-Docker assignment demonstrating how to containerize a simple ML workflow, run controlled experiments by varying hyperparameters, and capture results reproducibly.

## Summary
This project trains a neural network on MNIST inside a Docker container to ensure portability and reproducibility. Experiments vary epochs, batch size, and learning rate to observe effects on accuracy and execution time. See `Report/Report.pdf` for the full write-up with figures.

## Environment
- Machine: MacBook M3 (Apple Silicon, ARM64)
- Docker: 28.5.1
- Base image: `pytorch/pytorch:latest`
- Key files: `examples/mnist/main.py`, `examples/mnist/Dockerfile`, `Report/Report.pdf`

## Key Paths
- Training script (modified): `examples/mnist/main.py`
- Experiment runner: `examples/mnist/mnist_experiments.py`
- Dockerfile: `examples/mnist/Dockerfile`
- Dataset cache:
  - Inside container: `/data` (bind-mount recommended for reuse)
  - On host: create and mount `./data` from repo root
- Report: `Report/Report.pdf`

## Quick Start (Docker)
Follow these simple steps (as in the report):

1) Build the image:
```
docker build --no-cache -t mnist .
```

2) Run training:
```
docker run -it mnist
```

To capture output:
```
docker run -it mnist 2>&1 | tee docker-run.out
```

## Outputs and Logs
Defaults when running `mnist_experiments.py` from `examples/mnist/`:
- Docker run captures: `examples/mnist/docker-run-5ep.out`, `examples/mnist/docker-run-b256.out`
- Experiment CSV: `examples/mnist/mnist_results.csv`
- Experiment log: `examples/mnist/mnist_experiments.log`
- Plots:
  - `examples/mnist/accuracy_vs_epochs.png`, `examples/mnist/time_vs_epochs.png`
  - `examples/mnist/accuracy_vs_batch.png`, `examples/mnist/time_vs_batch.png`
  - `examples/mnist/accuracy_vs_lr.png`, `examples/mnist/time_vs_lr.png`

## Observations (from CSV)
Based on `examples/mnist/mnist_results.csv`:

- Epoch sweep (batch 64, lr 0.01): accuracy 92.0% (1) → 94.0% (3) → 95.0% (5–10) → 96.0% (15); time scales ≈65s → ≈916s (diminishing returns after ~5–10 epochs).
- Batch sweep (epochs 5, lr 0.01): time drops 364s (32) → 252s (256) while accuracy drops 96.0% → 92.0% (throughput vs generalization trade-off).
- LR sweep (epochs 5, batch 64): 0.001 underfits (87.0%); accuracy improves at 0.005 (93.0%), 0.01 (95.0%), peaking at 0.05 (98.0%) with similar times (~300–323s).

Quick links to plots:
- Accuracy: `examples/mnist/accuracy_vs_epochs.png`, `examples/mnist/accuracy_vs_batch.png`, `examples/mnist/accuracy_vs_lr.png`
- Time: `examples/mnist/time_vs_epochs.png`, `examples/mnist/time_vs_batch.png`, `examples/mnist/time_vs_lr.png`

## Figures
Results plots (generated by `examples/mnist/mnist_experiments.py`):

![Accuracy vs Epochs](examples/mnist/accuracy_vs_epochs.png)

![Accuracy vs Batch Size](examples/mnist/accuracy_vs_batch.png)

![Accuracy vs Learning Rate](examples/mnist/accuracy_vs_lr.png)

## Workflow (from Report)
The workflow followed these steps:
1. Clone the repository containing the MNIST training code:
```
git clone https://github.com/yourusername/mnist-docker.git
```
2. Write a Dockerfile to set up the environment, specifying the base image, copying necessary files, and setting the command to run the training script:
```
CMD ["python", "main.py", "--epochs=10", "--batch_size=32"]
```
3. Build the Docker image:
```
docker build --no-cache -t mnist .
```
4. Run the Docker container with the desired hyperparameters:
```
docker run -it mnist
```

## Observations and Results (summary)
- Increasing epochs improves accuracy but increases time.
- Larger batch sizes speed up per-epoch training but need more memory.
- Lower learning rates are more stable and can slightly improve accuracy at the cost of longer training.
See `Report/Report.pdf` for the full table and plots.

## Discussion and Analysis (summary)
- Hyperparameters (batch size, epochs, learning rate) control learning dynamics and computational efficiency.
- Dockerization provides reproducibility; `--no-cache` ensures fresh builds; note arch differences (amd64 vs arm64) on Apple Silicon.
- Conceptual mapping: containerization/reproducibility, hyperparameter tuning, performance trade-offs, resource management, virtualization & scaling, and portability across architectures.

## Notes
- Only `examples/mnist` is included from the upstream examples; other example folders are intentionally ignored.
- Data directories and PDFs are intentionally tracked; common local artifacts, caches, and virtual environments are ignored via `.gitignore`.

## References
- Docker: https://docs.docker.com/
- MNIST dataset: http://yann.lecun.com/exdb/mnist/
