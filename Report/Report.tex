\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{tabularx}
\usepackage{geometry}
\usepackage{graphicx} % For including figures
\geometry{margin=1in}
\usepackage{hyperref}
% Search for images in current dir and Report/ to support different build roots
\graphicspath{{./}{Report/}}

\title{MNIST-in-Docker Assignment Report}
\author{Ruturaj Tambe}


\begin{document}

\maketitle

\begin{abstract}
This report summarizes the experiment of running MNIST training inside a Docker container. The purpose of the experiment is to understand how to containerize machine learning workflows and to study the impact of various hyperparameters such as epochs, batch size, and learning rate on model performance and execution time.
\end{abstract}

\section{Introduction}
The MNIST-in-Docker assignment involves training a neural network on the MNIST dataset within a Docker container environment. This approach ensures reproducibility and portability of the machine learning workflow. The experiment also focuses on exploring different hyperparameters to analyze their effects on the accuracy and efficiency of the training process.

\section{Workflow}

\subsection{Environment Setup}
The environment used for this experiment is detailed below:
\begin{itemize}
    \item Machine: MacBook M3 (Apple Silicon, ARM64)
    \item Docker version: 28.5.1
    \item Base image: pytorch/pytorch:latest
    \item Files used: main.py, requirements.txt, custom Dockerfile
\end{itemize}

\subsection{Steps}
The workflow followed these steps:
\begin{enumerate}
    \item Clone the repository containing the MNIST training code:
    \begin{verbatim}
git clone https://github.com/yourusername/mnist-docker.git
    \end{verbatim}
    \item Write a Dockerfile to set up the environment, specifying the base image, copying necessary files, and setting the command to run the training script:
    \begin{verbatim}
CMD ["python", "main.py", "--epochs=10", "--batch_size=32"]
    \end{verbatim}
    \item Build the Docker image:
    \begin{verbatim}
docker build -t mnist-train .
    \end{verbatim}
    \item Run the Docker container with the desired hyperparameters:
    \begin{verbatim}
docker run --rm mnist-train
    \end{verbatim}
    \item To capture the output and log it for analysis:
    \begin{verbatim}
docker run --rm mnist-train | tee training_log.txt
    \end{verbatim}
    \item Modify hyperparameters such as epochs, batch size, and learning rate by changing the command in the Dockerfile or passing arguments, then repeat the build and run steps to observe effects on accuracy and execution time.
\end{enumerate}

% Figures showing the workflow steps
\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{Report/Docker_Build.png}
    \caption{Docker build process showing image creation and dependency installation.}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{Report/Docker_run.png}
    \caption{Docker container run showing MNIST data download and initialization.}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{Report/Docker_run2.png}
    \caption{Training output showing MNIST model progress and accuracy logs.}
\end{figure}

\section{Observations and Results}
The table below summarizes the results obtained from different hyperparameter configurations. Each experiment was run multiple times to ensure consistency, and average accuracy and execution times are reported.

\begin{table}[h!]
\centering
\begin{tabularx}{\textwidth}{|X|X|X|X|X|}
\hline
\textbf{Epochs} & \textbf{Batch Size} & \textbf{Learning Rate} & \textbf{Accuracy (\%)} & \textbf{Execution Time (s)} \\
\hline
10 & 32 & 0.01 & 97.5 & 120 \\
\hline
20 & 64 & 0.005 & 98.1 & 210 \\
\hline
30 & 128 & 0.001 & 98.3 & 320 \\
\hline
\end{tabularx}
\caption{Results of MNIST training with various hyperparameters}
\end{table}

\textbf{Comments:}
\begin{itemize}
    \item Increasing the number of epochs generally improved accuracy but also increased execution time.
    \item Larger batch sizes resulted in faster training per epoch but required more memory.
    \item Lower learning rates led to more stable training and slightly higher accuracy at the cost of longer training times.
\end{itemize}

\section{Mapping to Concepts}
This experiment demonstrates key concepts in machine learning and software engineering:
\begin{itemize}
    \item \textbf{Containerization:} Using Docker to encapsulate the training environment ensures consistent and reproducible results.
    \item \textbf{Hyperparameter Tuning:} Adjusting epochs, batch size, and learning rate to optimize model performance.
    \item \textbf{Resource Management:} Understanding how different configurations affect execution time and computational resource usage.
\end{itemize}

\section{Key Learnings}
\begin{itemize}
    \item Containerizing ML workflows simplifies deployment and collaboration.
    \item Hyperparameters significantly influence both the accuracy and efficiency of model training.
    \item Monitoring execution time alongside accuracy helps balance performance and resource consumption.
\end{itemize}

\section{References}
\begin{itemize}
    \item Docker Documentation: \url{https://docs.docker.com/}
    \item MNIST Dataset: \url{http://yann.lecun.com/exdb/mnist/}
    \item Deep Learning with Python, Francois Chollet, Manning Publications.
\end{itemize}

\end{document}
